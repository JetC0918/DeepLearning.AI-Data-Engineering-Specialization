## **[Course 2 - Source Systems, Data Ingestion, and Pipelines](https://www.coursera.org/learn/source-systems-data-ingestion-and-pipelines)**

This course consists of 4 weeks of content and covers 
these main learning objectives: 
   
1. **Understanding Source Systems**  
   - Explore different types of source systems, including databases, object storage, and streaming systems, 
        and how to interact with them in data engineering workflows.
  
2. **Data Ingestion & DataOps**  
   - Learn the complexities of data ingestion, focusing on how critical this step is in the data pipeline 
        process, and discover the importance of DataOps in maintaining quality and performance.

3. **Orchestration of Data Pipelines**  
   - Implement orchestration of end-to-end data pipelines, automating tasks for efficient data workflows.

4. **Structured vs. Unstructured Data**  
   - Understand the growing importance of ingesting and processing not just structured data, but also 
        unstructured data such as text, images, and videos.

5. **Monitoring Workflows**  
   - Learn about monitoring data pipelines to ensure quality, performance, and data completeness, 
        and explore tools for handling gaps or issues in the ingestion process.

6. **Future of Data Engineering**  
   - Prepare for the future of data engineering, which will increasingly focus on unstructured data, 
        creating more job opportunities and exciting challenges.  
        
### **Course Structure**:

- [Week 1](./Week%201): **Working with Source Systems** - Learn about common source systems and 
        how to connect and troubleshoot issues with them.  
- [Week 2](./Week%202/): **Data Ingestion** - Explore batch and streaming ingestion patterns, 
        build pipelines, and compare ETL vs. ELT paradigms using AWS services.
- [Week 3](./Week%203/): **DataOps** - Study DataOps automation, CI/CD, and observability practices 
        using tools like Terraform, Great Expectations, and Amazon CloudWatch.
- [Week 4](./Week%204/): **Orchestration, Monitoring, and Automating Data Pipelines** - Focus on 
        orchestrating data pipelines with Airflow, exploring its core components and how to manage DAGs. 


### Skill Gained 
- Networking on the Cloud 
- DataOps 
- Batch and Streaming Ingestion 
- Data orchestration 
- Infrastructure as Code (IaC)